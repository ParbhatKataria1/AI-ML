{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c510427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5474/1342396935.py:13: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./amazon_sales_report.csv\", parse_dates=['Date'])\n",
      "/tmp/ipykernel_5474/1342396935.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\"./amazon_sales_report.csv\", parse_dates=['Date'])\n",
      "/tmp/ipykernel_5474/1342396935.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['sales_pct_change_7d'].replace([np.inf,-np.inf],0,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1423\n",
      "[LightGBM] [Info] Number of data points in the train set: 13147, number of used features: 40\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 639.807180\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 18.5736\ttest's rmse: 26.1405\n",
      "[200]\ttrain's rmse: 14.1525\ttest's rmse: 24.3346\n",
      "Early stopping, best iteration is:\n",
      "[184]\ttrain's rmse: 14.5599\ttest's rmse: 24.0233\n",
      "First 5 predictions: [ 422.96343838  423.47580489  -10.61286624 1086.15589606 1084.68815514]\n",
      "First 5 predictions: 65057     418.0\n",
      "63524     418.0\n",
      "67901       0.0\n",
      "66075    1125.0\n",
      "62124    1125.0\n",
      "Name: Amount, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load dataset\n",
    "# -----------------------------\n",
    "df = pd.read_csv(\"./amazon_sales_report.csv\", parse_dates=['Date'])\n",
    "df = df[df['Status'].str.lower() == 'shipped']\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Time-based features\n",
    "# -----------------------------\n",
    "df['day_of_week'] = df['Date'].dt.dayofweek\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['quarter'] = df['Date'].dt.quarter\n",
    "df['day_of_month'] = df['Date'].dt.day\n",
    "df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)\n",
    "df['week_of_year'] = df['Date'].dt.isocalendar().week.astype(int)\n",
    "df['year'] = df['Date'].dt.year\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Holidays\n",
    "# -----------------------------\n",
    "years = df['Date'].dt.year.unique()\n",
    "ind_holidays = holidays.India(years=years)\n",
    "holiday_df = pd.DataFrame(list(ind_holidays.items()), columns=['Date','holiday_tag'])\n",
    "holiday_df['Date'] = pd.to_datetime(holiday_df['Date'])\n",
    "df = df.merge(holiday_df, on='Date', how='left')\n",
    "df['holiday_tag'] = df['holiday_tag'].fillna('None')\n",
    "df = pd.get_dummies(df, columns=['holiday_tag'], drop_first=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Promotion features\n",
    "# -----------------------------\n",
    "df['promotion_flag'] = df['promotion-ids'].notnull().astype(int)\n",
    "df = df.sort_values(['SKU','Date'])\n",
    "df['recent_promo_count_7d'] = df.groupby('SKU')['promotion_flag'].rolling(7, min_periods=1).sum().reset_index(0,drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Price / SKU features\n",
    "# -----------------------------\n",
    "df['amount_per_unit'] = df['Amount'] / df['Qty']\n",
    "df['SKU_popularity_score'] = df.groupby('SKU')['Qty'].transform('sum')\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Lag & rolling features\n",
    "# -----------------------------\n",
    "for lag in [1,7,30]:\n",
    "    df[f'sales_t-{lag}'] = df.groupby('SKU')['Qty'].shift(lag)\n",
    "\n",
    "df['rolling_avg_7d'] = df.groupby('SKU')['Qty'].transform(lambda x: x.rolling(7, min_periods=1).mean())\n",
    "df['rolling_avg_30d'] = df.groupby('SKU')['Qty'].transform(lambda x: x.rolling(30, min_periods=1).mean())\n",
    "df['sales_diff_1d'] = df['Qty'] - df['sales_t-1']\n",
    "df['sales_pct_change_7d'] = (df['Qty'] - df['sales_t-7']) / df['sales_t-7']\n",
    "df['sales_pct_change_7d'].replace([np.inf,-np.inf],0,inplace=True)\n",
    "\n",
    "df['month_year'] = df['Date'].dt.to_period('M')\n",
    "df['cumulative_month_sales'] = df.groupby(['SKU','month_year'])['Qty'].cumsum()\n",
    "\n",
    "# -----------------------------\n",
    "# 7. One-hot encoding for categorical features\n",
    "# -----------------------------\n",
    "df = pd.get_dummies(df, columns=['Sales Channel','Fulfilment','ship-service-level','Category'], drop_first=True)\n",
    "df['B2B'] = df['B2B'].fillna(0).astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Geographic features\n",
    "# -----------------------------\n",
    "df['city_sales_avg'] = df.groupby(['SKU','ship-city'])['Qty'].transform('mean').fillna(0)\n",
    "df['state_sales_avg'] = df.groupby(['SKU','ship-state'])['Qty'].transform('mean').fillna(0)\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Statistical features\n",
    "# -----------------------------\n",
    "df['rolling_std_7d'] = df.groupby('SKU')['Qty'].transform(lambda x: x.rolling(7, min_periods=1).std())\n",
    "df['sales_momentum'] = df['rolling_avg_7d'] / (df['rolling_avg_30d'] + 1e-6)\n",
    "\n",
    "# -----------------------------\n",
    "# 10. Drop unnecessary columns\n",
    "# -----------------------------\n",
    "drop_cols = ['Order ID','ASIN','fulfilled-by','Unnamed: 22','promotion-ids',\n",
    "             'ship-city','ship-state','ship-country','ship-postal-code']\n",
    "\n",
    "df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)\n",
    "df.dropna(subset=['sales_t-1','sales_t-7','sales_t-30'], inplace=True)\n",
    "df['Qty'] = df['Qty'].astype(int)\n",
    "\n",
    "# -----------------------------\n",
    "# 11. Encode remaining categorical columns\n",
    "# -----------------------------\n",
    "cat_cols = ['Status','Style','SKU','Size','Courier Status','currency']\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# -----------------------------\n",
    "# 12. Train-test split (time-based)\n",
    "# -----------------------------\n",
    "train = df[df['Date'] < '2022-06-01']\n",
    "test = df[df['Date'] >= '2022-06-01']\n",
    "\n",
    "\n",
    "col = 'Amount'\n",
    "\n",
    "# Compute mean ignoring zeros and NaNs\n",
    "df['Amount'] = df['Amount'].fillna(df['Amount'].mean())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target = 'Amount'\n",
    "features = [c for c in df.columns if c not in ['Amount','Date','month_year']]\n",
    "\n",
    "\n",
    "X_train, y_train = train[features], train[target]\n",
    "X_test, y_test = test[features], test[target]\n",
    "\n",
    "# -----------------------------\n",
    "# 13. LightGBM Dataset\n",
    "# -----------------------------\n",
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_cols)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, categorical_feature=cat_cols)\n",
    "\n",
    "params = {\n",
    "    'objective':'regression',\n",
    "    'metric':'rmse',\n",
    "    'boosting_type':'gbdt',\n",
    "    'num_leaves':128,\n",
    "    'learning_rate':0.05,\n",
    "    'feature_fraction':0.9,\n",
    "    'bagging_fraction':0.8,\n",
    "    'bagging_freq':5\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# 14. Train model\n",
    "# -----------------------------\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data,test_data],\n",
    "    valid_names=['train','test'],\n",
    "    num_boost_round=2000,\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 15. Predict & evaluate\n",
    "# -----------------------------\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"First 5 predictions:\", y_pred[:5])\n",
    "print(\"First 5 predictions:\", y_test[:5])\n",
    "\n",
    "# print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "# # Safe MAPE\n",
    "# epsilon = 1e-6\n",
    "# mape = np.mean(np.abs((y_test - y_pred)/(y_test+epsilon))) * 100\n",
    "# print(\"MAPE:\", mape)\n",
    "\n",
    "# -----------------------------\n",
    "# 16. Cleanup\n",
    "# -----------------------------\n",
    "del model\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
